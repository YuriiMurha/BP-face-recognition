"""FaceNet Recognizer for Face Embedding Extraction

This is the migrated version of the FaceNet recognizer
with improved error handling and configuration flexibility.
"""

import numpy as np
import tensorflow as tf
import cv2
from typing import Optional, Dict, Any
from pathlib import Path
import logging

from bp_face_recognition.vision.recognition.base import (
    BaseRecognizer,
    EmbeddingMetadata,
)

logger = logging.getLogger(__name__)


class FaceNetRecognizer(BaseRecognizer):
    """
    FaceNet model for face embedding extraction.

    Pre-trained FaceNet that extracts 128-dimensional face embeddings
    suitable for face recognition and similarity matching.
    """

    def __init__(
        self,
        model_path: Optional[str] = None,
        input_size: tuple = (160, 160),
        normalize: bool = True,
    ):
        """
        Initialize FaceNet recognizer.

        Args:
            model_path: Path to FaceNet model file
            input_size: Expected input image size (height, width)
            normalize: Whether to normalize pixel values
        """
        super().__init__(input_size, normalize)

        self.model_path = model_path or self._get_default_model_path()
        self.embedding_size = 128

        # Load FaceNet model
        try:
            logger.info(f"Loading FaceNet model from: {self.model_path}")
            self.model = tf.keras.models.load_model(
                self.model_path,
                compile=False,
                safe_mode=False,  # FaceNet contains Lambda layers
            )
            self._initialized = True
            logger.info("FaceNet model loaded successfully")

        except Exception as e:
            logger.error(f"Failed to load FaceNet model: {e}")
            self.model = None
            self._initialized = False

    def _get_default_model_path(self) -> str:
        """
        Get default FaceNet model path.

        Returns:
            Path to default FaceNet model
        """
        # Look in the recognition models directory first
        project_root = Path(__file__).parent.parent.parent.parent
        default_path = (
            project_root
            / "src/bp_face_recognition/vision/recognition/models/facenet_keras.h5"
        )

        if default_path.exists():
            return str(default_path)

        # Fallback to old location
        old_path = project_root / "models/FaceNet/facenet_keras.h5"
        if old_path.exists():
            logger.warning(f"Using legacy model path: {old_path}")
            return str(old_path)

        # Create model if it doesn't exist
        raise FileNotFoundError(
            f"FaceNet model not found at {default_path} or {old_path}"
        )

    def get_embedding(self, face_image: np.ndarray) -> np.ndarray:
        """
        Extract 128D face embedding using FaceNet.

        Args:
            face_image: Input face image array

        Returns:
            128-dimensional embedding vector
        """
        if not self._validate_face_image(face_image):
            return np.array([])

        if self.model is None:
            logger.error("FaceNet model not loaded")
            return np.array([])

        try:
            # FaceNet preprocessing
            processed_face = self._preprocess_face(face_image)

            # FaceNet expects (1, height, width, channels) format
            samples = np.expand_dims(processed_face, axis=0)

            # Extract embedding
            embedding = self.model.predict(samples, verbose=0)

            # Extract the embedding vector (usually 128D)
            if len(embedding.shape) == 2:
                embedding = embedding[0]

            # Ensure 1D output
            if len(embedding.shape) > 1:
                embedding = embedding.reshape(-1)

            # Validate output
            if not self._validate_embedding(embedding):
                logger.warning("Invalid embedding generated by FaceNet")
                return np.array([])

            return embedding

        except Exception as e:
            logger.error(f"Face embedding extraction failed: {e}")
            return np.array([])

    def get_embedding_with_metadata(self, face_image: np.ndarray) -> EmbeddingMetadata:
        """
        Extract embedding with metadata.

        Args:
            face_image: Input face image

        Returns:
            EmbeddingMetadata with embedding and metadata
        """
        import time

        start_time = time.time()

        embedding = self.get_embedding(face_image)
        processing_time = time.time() - start_time

        confidence = 1.0 if len(embedding) > 0 else 0.0

        return EmbeddingMetadata(
            embedding=embedding,
            confidence=confidence,
            processing_time=processing_time,
            face_quality=self._estimate_face_quality(face_image),
        )

    def _estimate_face_quality(self, face_image: np.ndarray) -> float:
        """
        Estimate face quality based on image characteristics.

        Args:
            face_image: Input face image

        Returns:
            Quality score between 0.0 and 1.0
        """
        try:
            # Simple quality metrics
            if len(face_image.shape) < 2:
                return 0.0

            # Check image sharpness (variance)
            gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
            laplacian = cv2.Laplacian(gray, cv2.CV_64F)
            sharpness = np.var(laplacian)

            # Normalize sharpness to [0, 1]
            quality_score = min(sharpness / 1000.0, 1.0)

            return max(quality_score, 0.1)

        except Exception:
            return 0.5  # Default quality

    def get_recognizer_info(self) -> Dict[str, Any]:
        """
        Get information about the recognizer.

        Returns:
            Dictionary with recognizer metadata
        """
        info = super().get_recognizer_info()
        info.update(
            {
                "model_path": self.model_path,
                "embedding_size": self.embedding_size,
                "model_type": "FaceNet",
                "input_size": self.input_size,
                "preprocessing": {
                    "normalize": self.normalize,
                    "mean_subtraction": True,
                    "resize_method": "bilinear",
                },
            }
        )

        return info

    def verify_model(self) -> Dict[str, Any]:
        """
        Verify the loaded model by running a test prediction.

        Returns:
            Dictionary with verification results
        """
        if not self._initialized:
            return {"verified": False, "error": "Model not initialized"}

        try:
            # Create a dummy face image
            dummy_face = np.random.randint(0, 255, (160, 160, 3), dtype=np.uint8)

            # Test embedding extraction
            embedding = self.get_embedding(dummy_face)

            verification_result = {
                "verified": len(embedding) == self.embedding_size,
                "embedding_shape": embedding.shape,
                "embedding_norm": np.linalg.norm(embedding),
                "model_loaded": self.model is not None,
            }

            if verification_result["verified"]:
                logger.info("FaceNet model verification passed")
            else:
                logger.warning("FaceNet model verification failed")

            return verification_result

        except Exception as e:
            logger.error(f"Model verification failed: {e}")
            return {"verified": False, "error": str(e)}
